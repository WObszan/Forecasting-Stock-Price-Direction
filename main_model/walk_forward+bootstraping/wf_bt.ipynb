{
 "cells": [
  {
   "cell_type": "code",
   "id": "0a6d0563",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:04:51.570072Z",
     "start_time": "2026-01-24T22:04:51.566388Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ],
   "outputs": [],
   "execution_count": 93
  },
  {
   "cell_type": "markdown",
   "id": "1edef7fa",
   "metadata": {},
   "source": [
    "# Target"
   ]
  },
  {
   "cell_type": "code",
   "id": "12e2f7e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:04:51.588159Z",
     "start_time": "2026-01-24T22:04:51.584892Z"
    }
   },
   "source": [
    "def get_target(input_df, ticker):\n",
    "    df = input_df.copy()\n",
    "    df[\"Target\"] = (df[f\"Close_{ticker}\"].shift(-1) > df[f\"Close_{ticker}\"]).astype(int)\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Target TBM ( Triple Barrier Method)",
   "id": "b5226bedb743735d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:04:51.613495Z",
     "start_time": "2026-01-24T22:04:51.609232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_tbm_target(df, ticker, horizon=5, pt_sl=[0.8,0.8]):\n",
    "    df = df.copy()\n",
    "    close = df[f'Close_{ticker}']\n",
    "    \n",
    "    log_ret = np.log(close / close.shift(1))\n",
    "    volatility = log_ret.rolling(window=20).std()\n",
    "    \n",
    "    targets = pd.Series(index=df.index, dtype=float)\n",
    "    \n",
    "    for i in range(len(df) - horizon):\n",
    "        price_start = close.iloc[i]\n",
    "        current_vol = volatility.iloc[i] ### dynamic barrier for each day\n",
    "        \n",
    "        upper_barrier = price_start * (1 + current_vol * pt_sl[0])\n",
    "        lower_barrier = price_start * (1 - current_vol * pt_sl[1])\n",
    "        \n",
    "        future_prices = close.iloc[i+1 : i+ 1 + horizon]\n",
    "        \n",
    "        targets.iloc[i] = 0\n",
    "        \n",
    "        for price_future in future_prices:\n",
    "            if price_future >= upper_barrier:\n",
    "                targets.iloc[i] = 1 # profit taking hit\n",
    "                break\n",
    "            elif price_future <= lower_barrier:\n",
    "                targets.iloc[i] = -1 # stop loss hit\n",
    "                break\n",
    "    df['Target'] = targets\n",
    "    return df.dropna(subset=['Target'])"
   ],
   "id": "57cd8af5bb166577",
   "outputs": [],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "id": "597f8051",
   "metadata": {},
   "source": [
    "# Model: Ensemble (Voting Soft)"
   ]
  },
  {
   "cell_type": "code",
   "id": "2d267750",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:04:51.632795Z",
     "start_time": "2026-01-24T22:04:51.629076Z"
    }
   },
   "source": [
    "def build_ensemble_model():\n",
    "    lr_pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lr\", LogisticRegression(max_iter=2000, random_state=42))\n",
    "    ])\n",
    "\n",
    "    rf_pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"rf\", RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=4,\n",
    "            min_samples_leaf=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    svm_pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(\n",
    "            kernel=\"rbf\",\n",
    "            C=1.0,\n",
    "            gamma=\"scale\",\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    xgb_pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"xgb\", XGBClassifier(\n",
    "            n_estimators=50,\n",
    "            max_depth=3,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            eval_metric=\"logloss\"\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    model = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"lr\", lr_pipeline),\n",
    "            (\"rf\", rf_pipeline),\n",
    "            (\"svm\", svm_pipeline),\n",
    "            (\"xgb\", xgb_pipeline),\n",
    "        ],\n",
    "        voting=\"soft\"\n",
    "    )\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "id": "9c4f04c9",
   "metadata": {},
   "source": "### Sample Weights"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:04:51.652294Z",
     "start_time": "2026-01-24T22:04:51.649230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    def get_sample_weights(df, ticker, horizon=5):\n",
    "        # create a binary matrix indicating which days are covered by which barrier\n",
    "        num_rows = len(df)\n",
    "        concurrency = np.zeros(num_rows)\n",
    "\n",
    "        for i in range(num_rows - horizon):\n",
    "            concurrency[i  : i + horizon] += 1\n",
    "\n",
    "        uniqueness = 1.0 / np.maximum(concurrency, 1)\n",
    "\n",
    "        weights = pd.Series(index=df.index, dtype=float)\n",
    "        for i in range(num_rows - horizon):\n",
    "            weights.iloc[i] = uniqueness[i : i + horizon].mean()\n",
    "        \n",
    "        return weights.fillna(0)"
   ],
   "id": "b050efec6740a3b0",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Walk Forward validation with purging and embargo in validation\n",
   "id": "97dfdf85e9bc48ba"
  },
  {
   "cell_type": "code",
   "id": "1821dd77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:04:51.672610Z",
     "start_time": "2026-01-24T22:04:51.666293Z"
    }
   },
   "source": [
    "def walk_forward_validation_with_purging(\n",
    "    df,\n",
    "    features,\n",
    "    target_col=\"Target\",\n",
    "    date_col=\"DATE\",\n",
    "    start_year=2010,\n",
    "    first_train_end_year=2015,\n",
    "    last_test_year=2023,\n",
    "    horizon = 5,\n",
    "    embargo_pct = 0.01\n",
    "):\n",
    "    \"\"\"\n",
    "    Train: start_year -> train_end_year\n",
    "    Test : train_end_year+1\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.sort_values(date_col).reset_index(drop=True)\n",
    "\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    all_y_proba = []\n",
    "\n",
    "    fold_rows = []\n",
    "\n",
    "    sample_weights_all = get_sample_weights(df, horizon)\n",
    "    \n",
    "    for train_end_year in range(first_train_end_year, last_test_year):\n",
    "        test_year = train_end_year + 1\n",
    "\n",
    "        train_mask = (df[date_col].dt.year >= start_year) & (df[date_col].dt.year <= train_end_year)\n",
    "        test_mask = (df[date_col].dt.year == test_year)\n",
    "\n",
    "        train_df = df[train_mask]\n",
    "        test_df = df[test_mask]\n",
    "\n",
    "        # jeżeli jakiś rok nie ma danych to skip\n",
    "        if len(train_df) < 200 or len(test_df) < 50:\n",
    "            continue\n",
    "\n",
    "        ## Purging\n",
    "        train_df_purged = train_df.iloc[:-horizon]\n",
    "        weights_train = sample_weights_all.loc[train_df_purged.index] \n",
    "        \n",
    "        ## Embargo\n",
    "        embargo_size = int(len(df) * embargo_pct)\n",
    "        test_df_embargo = test_df.iloc[embargo_size:]\n",
    "        \n",
    "        if len(test_df_embargo) < 10: continue\n",
    "        \n",
    "        \n",
    "        X_train = train_df_purged[features]\n",
    "        y_train = train_df_purged[target_col]\n",
    "\n",
    "        X_test = test_df_embargo[features]\n",
    "        y_test = test_df_embargo[target_col]\n",
    "\n",
    "        model = build_ensemble_model()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test) \n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        auc = roc_auc_score(y_test, y_proba, average='weighted', multi_class='ovr')\n",
    "\n",
    "        fold_rows.append({\n",
    "            \"train_end_year\": train_end_year,\n",
    "            \"test_year\": test_year,\n",
    "            \"n_train\": len(train_df),\n",
    "            \"n_test\": len(test_df),\n",
    "            \"accuracy\": acc,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"roc_auc\": auc\n",
    "        })\n",
    "\n",
    "        all_y_true.extend(y_test.tolist())\n",
    "        all_y_pred.extend(y_pred.tolist())\n",
    "        all_y_proba.extend(y_proba.tolist())\n",
    "\n",
    "    folds_df = pd.DataFrame(fold_rows)\n",
    "\n",
    "    return folds_df, np.array(all_y_true), np.array(all_y_pred), np.array(all_y_proba)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "id": "1e70340a",
   "metadata": {},
   "source": [
    "# Block bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "id": "b22d0d17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:04:51.691916Z",
     "start_time": "2026-01-24T22:04:51.688028Z"
    }
   },
   "source": [
    "def block_bootstrap_accuracy(y_true, y_pred, block_size=20, n_bootstrap=1000, random_state=42):\n",
    "    \"\"\"\n",
    "    Bootstrap na wynikach testowych (y_true/y_pred), losowanie blokami.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n = len(y_true)\n",
    "\n",
    "    if n < block_size:\n",
    "        raise ValueError(\"Za mało danych do bootstrapa w tej konfiguracji.\")\n",
    "\n",
    "    acc_samples = []\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        sampled_idx = []\n",
    "\n",
    "        while len(sampled_idx) < n:\n",
    "            start = rng.integers(0, n - block_size + 1)\n",
    "            block = list(range(start, start + block_size))\n",
    "            sampled_idx.extend(block)\n",
    "\n",
    "        sampled_idx = sampled_idx[:n]\n",
    "        y_true_bs = y_true[sampled_idx]\n",
    "        y_pred_bs = y_pred[sampled_idx]\n",
    "\n",
    "        acc = accuracy_score(y_true_bs, y_pred_bs)\n",
    "        acc_samples.append(acc)\n",
    "\n",
    "    acc_samples = np.array(acc_samples)\n",
    "    ci_low = np.percentile(acc_samples, 2.5)\n",
    "    ci_high = np.percentile(acc_samples, 97.5)\n",
    "\n",
    "    return acc_samples, ci_low, ci_high\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "id": "abe72a57",
   "metadata": {},
   "source": [
    "# Walk_forward + Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "id": "c3626543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:04:51.710206Z",
     "start_time": "2026-01-24T22:04:51.706327Z"
    }
   },
   "source": [
    "def run_stage4_for_ticker(df_raw, ticker, selected_features):\n",
    "    df = get_tbm_target(df_raw, ticker)\n",
    "\n",
    "    selected_features = [f for f in selected_features if f in df.columns]\n",
    "\n",
    "    folds_df, y_true_all, y_pred_all, y_proba_all = walk_forward_validation_with_purging(\n",
    "        df=df,\n",
    "        features=selected_features,\n",
    "        target_col=\"Target\",\n",
    "        date_col=\"DATE\",\n",
    "        start_year=2010,\n",
    "        first_train_end_year=2015,\n",
    "        last_test_year=2023 \n",
    "    )\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\" WALK-FORWARD RESULTS for {ticker}\")\n",
    "    print(folds_df)\n",
    "\n",
    "    print(\"\\n--- Summary ---\")\n",
    "    print(\"Mean accuracy:\", folds_df[\"accuracy\"].mean())\n",
    "    print(\"Std  accuracy:\", folds_df[\"accuracy\"].std())\n",
    "    print(\"Mean roc_auc :\", folds_df[\"roc_auc\"].mean())\n",
    "\n",
    "    # Block Bootstrap\n",
    "    acc_samples, ci_low, ci_high = block_bootstrap_accuracy(\n",
    "        y_true=y_true_all,\n",
    "        y_pred=y_pred_all,\n",
    "        block_size=20,\n",
    "        n_bootstrap=1000\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\" BLOCK BOOTSTRAP for {ticker}\")\n",
    "    print(f\"95% CI accuracy: [{ci_low:.4f}, {ci_high:.4f}]\")\n",
    "    print(f\"Bootstrap mean accuracy: {acc_samples.mean():.4f}\")\n",
    "\n",
    "    return folds_df, acc_samples\n"
   ],
   "outputs": [],
   "execution_count": 100
  },
  {
   "cell_type": "markdown",
   "id": "e97fdf69",
   "metadata": {},
   "source": [
    "# Example use"
   ]
  },
  {
   "cell_type": "code",
   "id": "6fd375e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:14:29.956345Z",
     "start_time": "2026-01-24T22:14:17.143909Z"
    }
   },
   "source": [
    "\n",
    "tickers = [\"AAPL\", \"GOOGL\", \"MSFT\"]\n",
    "measurments = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "#measurments = ['accuracy'] ##just for test\n",
    "\n",
    "with open(\"../../models_results/feature_dict.json\", \"r\") as f:\n",
    "    feature_dict = json.load(f)\n",
    "\n",
    "\n",
    "def get_all_features(df):\n",
    "    return [c for c in df.columns if c not in [\"DATE\", \"index\", \"Target\"]]\n",
    "\n",
    "for share in tickers:\n",
    "    data = pd.read_csv(f\"../../data/all_data/all_{share}_data.csv\")\n",
    "    df_tmp = get_tbm_target(data, share)\n",
    "    features_aapl = get_all_features(df_tmp)\n",
    "    print(f\"------{share}-----\")\n",
    "    for stat in measurments:\n",
    "        selected_features = feature_dict[share][stat]\n",
    "        print(f\"Selected features for {share} based on {stat}:\")\n",
    "        # print(f\"Running for {share} with all features ({len(features_aapl)})\")\n",
    "        # run_stage4_for_ticker(data, share, features_aapl)\n",
    "        print(f\"Running for {share} with selected features ({len(selected_features)})\")\n",
    "        run_stage4_for_ticker(data, share, selected_features)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------AAPL-----\n",
      "Selected features for AAPL based on accuracy:\n",
      "Running for AAPL with selected features (10)\n",
      "============================================================\n",
      " WALK-FORWARD RESULTS for AAPL\n",
      "   train_end_year  test_year  n_train  n_test  accuracy  precision    recall  \\\n",
      "0            2015       2016      973     252  0.435780   0.365772  0.435780   \n",
      "1            2016       2017     1225     251  0.364055   0.374021  0.364055   \n",
      "2            2017       2018     1476     251  0.414747   0.350683  0.414747   \n",
      "3            2018       2019     1727     252  0.623853   0.583294  0.623853   \n",
      "4            2019       2020     1979     253  0.465753   0.441719  0.465753   \n",
      "5            2020       2021     2232     252  0.541284   0.433733  0.541284   \n",
      "6            2021       2022     2484     251  0.470046   0.515379  0.470046   \n",
      "7            2022       2023     2735     250  0.439815   0.398692  0.439815   \n",
      "\n",
      "    roc_auc  \n",
      "0  0.487668  \n",
      "1  0.487969  \n",
      "2  0.483683  \n",
      "3  0.489715  \n",
      "4  0.512231  \n",
      "5  0.518424  \n",
      "6  0.502128  \n",
      "7  0.441163  \n",
      "\n",
      "--- Summary ---\n",
      "Mean accuracy: 0.4694166996165363\n",
      "Std  accuracy: 0.08029141628030356\n",
      "Mean roc_auc : 0.4903723242748419\n",
      "\n",
      "============================================================\n",
      " BLOCK BOOTSTRAP for AAPL\n",
      "95% CI accuracy: [0.4339, 0.5069]\n",
      "Bootstrap mean accuracy: 0.4705\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'precision'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[102]\u001B[39m\u001B[32m, line 18\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m------\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mshare\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m-----\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m stat \u001B[38;5;129;01min\u001B[39;00m measurments:\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m     selected_features = \u001B[43mfeature_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[43mshare\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mstat\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m     19\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mSelected features for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mshare\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m based on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstat\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     20\u001B[39m     \u001B[38;5;66;03m# print(f\"Running for {share} with all features ({len(features_aapl)})\")\u001B[39;00m\n\u001B[32m     21\u001B[39m     \u001B[38;5;66;03m# run_stage4_for_ticker(data, share, features_aapl)\u001B[39;00m\n",
      "\u001B[31mKeyError\u001B[39m: 'precision'"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "id": "362594b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:05:15.376044Z",
     "start_time": "2026-01-24T22:05:15.374042Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
