{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a6d0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edef7fa",
   "metadata": {},
   "source": [
    "# Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12e2f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(input_df, ticker):\n",
    "    df = input_df.copy()\n",
    "    df[\"Target\"] = (df[f\"Close_{ticker}\"].shift(-1) > df[f\"Close_{ticker}\"]).astype(int)\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597f8051",
   "metadata": {},
   "source": [
    "# Model: Ensemble (Voting Soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d267750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ensemble_model():\n",
    "    lr_pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lr\", LogisticRegression(max_iter=2000, random_state=42))\n",
    "    ])\n",
    "\n",
    "    rf_pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"rf\", RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=4,\n",
    "            min_samples_leaf=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    svm_pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(\n",
    "            kernel=\"rbf\",\n",
    "            C=1.0,\n",
    "            gamma=\"scale\",\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    xgb_pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"xgb\", XGBClassifier(\n",
    "            n_estimators=50,\n",
    "            max_depth=3,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            eval_metric=\"logloss\"\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    model = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"lr\", lr_pipeline),\n",
    "            (\"rf\", rf_pipeline),\n",
    "            (\"svm\", svm_pipeline),\n",
    "            (\"xgb\", xgb_pipeline),\n",
    "        ],\n",
    "        voting=\"soft\"\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4f04c9",
   "metadata": {},
   "source": [
    "# Walk Forward validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1821dd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_validation(\n",
    "    df,\n",
    "    features,\n",
    "    target_col=\"Target\",\n",
    "    date_col=\"DATE\",\n",
    "    start_year=2010,\n",
    "    first_train_end_year=2015,\n",
    "    last_test_year=2023\n",
    "):\n",
    "    \"\"\"\n",
    "    Train: start_year -> train_end_year\n",
    "    Test : train_end_year+1\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.sort_values(date_col).reset_index(drop=True)\n",
    "\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    all_y_proba = []\n",
    "\n",
    "    fold_rows = []\n",
    "\n",
    "    for train_end_year in range(first_train_end_year, last_test_year):\n",
    "        test_year = train_end_year + 1\n",
    "\n",
    "        train_mask = (df[date_col].dt.year >= start_year) & (df[date_col].dt.year <= train_end_year)\n",
    "        test_mask = (df[date_col].dt.year == test_year)\n",
    "\n",
    "        train_df = df[train_mask]\n",
    "        test_df = df[test_mask]\n",
    "\n",
    "        # jeżeli jakiś rok nie ma danych to skip\n",
    "        if len(train_df) < 200 or len(test_df) < 50:\n",
    "            continue\n",
    "\n",
    "        X_train = train_df[features]\n",
    "        y_train = train_df[target_col]\n",
    "\n",
    "        X_test = test_df[features]\n",
    "        y_test = test_df[target_col]\n",
    "\n",
    "        model = build_ensemble_model()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]  # ważne dla ROC-AUC\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "        fold_rows.append({\n",
    "            \"train_end_year\": train_end_year,\n",
    "            \"test_year\": test_year,\n",
    "            \"n_train\": len(train_df),\n",
    "            \"n_test\": len(test_df),\n",
    "            \"accuracy\": acc,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"roc_auc\": auc\n",
    "        })\n",
    "\n",
    "        all_y_true.extend(y_test.tolist())\n",
    "        all_y_pred.extend(y_pred.tolist())\n",
    "        all_y_proba.extend(y_proba.tolist())\n",
    "\n",
    "    folds_df = pd.DataFrame(fold_rows)\n",
    "\n",
    "    return folds_df, np.array(all_y_true), np.array(all_y_pred), np.array(all_y_proba)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e70340a",
   "metadata": {},
   "source": [
    "# Block bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22d0d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_bootstrap_accuracy(y_true, y_pred, block_size=20, n_bootstrap=1000, random_state=42):\n",
    "    \"\"\"\n",
    "    Bootstrap na wynikach testowych (y_true/y_pred), losowanie blokami.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n = len(y_true)\n",
    "\n",
    "    if n < block_size:\n",
    "        raise ValueError(\"Za mało danych do bootstrapa w tej konfiguracji.\")\n",
    "\n",
    "    acc_samples = []\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        sampled_idx = []\n",
    "\n",
    "        while len(sampled_idx) < n:\n",
    "            start = rng.integers(0, n - block_size + 1)\n",
    "            block = list(range(start, start + block_size))\n",
    "            sampled_idx.extend(block)\n",
    "\n",
    "        sampled_idx = sampled_idx[:n]\n",
    "        y_true_bs = y_true[sampled_idx]\n",
    "        y_pred_bs = y_pred[sampled_idx]\n",
    "\n",
    "        acc = accuracy_score(y_true_bs, y_pred_bs)\n",
    "        acc_samples.append(acc)\n",
    "\n",
    "    acc_samples = np.array(acc_samples)\n",
    "    ci_low = np.percentile(acc_samples, 2.5)\n",
    "    ci_high = np.percentile(acc_samples, 97.5)\n",
    "\n",
    "    return acc_samples, ci_low, ci_high\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe72a57",
   "metadata": {},
   "source": [
    "# Walk_forward + Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3626543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stage4_for_ticker(df_raw, ticker, selected_features):\n",
    "    df = get_target(df_raw, ticker)\n",
    "\n",
    "    # upewnij się że feature istnieją\n",
    "    selected_features = [f for f in selected_features if f in df.columns]\n",
    "\n",
    "    folds_df, y_true_all, y_pred_all, y_proba_all = walk_forward_validation(\n",
    "        df=df,\n",
    "        features=selected_features,\n",
    "        target_col=\"Target\",\n",
    "        date_col=\"DATE\",\n",
    "        start_year=2010,\n",
    "        first_train_end_year=2015,\n",
    "        last_test_year=2023  # ustaw pod swój dataset\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\" WALK-FORWARD RESULTS for {ticker}\")\n",
    "    print(folds_df)\n",
    "\n",
    "    print(\"\\n--- Summary ---\")\n",
    "    print(\"Mean accuracy:\", folds_df[\"accuracy\"].mean())\n",
    "    print(\"Std  accuracy:\", folds_df[\"accuracy\"].std())\n",
    "    print(\"Mean roc_auc :\", folds_df[\"roc_auc\"].mean())\n",
    "\n",
    "    # Block Bootstrap\n",
    "    acc_samples, ci_low, ci_high = block_bootstrap_accuracy(\n",
    "        y_true=y_true_all,\n",
    "        y_pred=y_pred_all,\n",
    "        block_size=20,\n",
    "        n_bootstrap=1000\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\" BLOCK BOOTSTRAP for {ticker}\")\n",
    "    print(f\"95% CI accuracy: [{ci_low:.4f}, {ci_high:.4f}]\")\n",
    "    print(f\"Bootstrap mean accuracy: {acc_samples.mean():.4f}\")\n",
    "\n",
    "    return folds_df, acc_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97fdf69",
   "metadata": {},
   "source": [
    "# Example use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fd375e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------AAPL-----\n",
      "Selected features for AAPL based on accuracy:\n",
      "Running for AAPL with selected features (11)\n",
      "============================================================\n",
      " WALK-FORWARD RESULTS for AAPL\n",
      "   train_end_year  test_year  n_train  n_test  accuracy  precision    recall  \\\n",
      "0            2015       2016     1510     252  0.515873   0.522822  0.947368   \n",
      "1            2016       2017     1762     251  0.482072   0.571429  0.231884   \n",
      "2            2017       2018     2013     251  0.482072   0.495798  0.457364   \n",
      "3            2018       2019     2264     252  0.559524   0.575000  0.938776   \n",
      "4            2019       2020     2516     253  0.553360   0.566667  0.744526   \n",
      "5            2020       2021     2769     252  0.563492   0.552174  0.947761   \n",
      "6            2021       2022     3021     251  0.474104   0.468468  0.881356   \n",
      "7            2022       2023     3272     250  0.548000   0.595745  0.600000   \n",
      "\n",
      "    roc_auc  \n",
      "0  0.493334  \n",
      "1  0.515775  \n",
      "2  0.499238  \n",
      "3  0.502883  \n",
      "4  0.572238  \n",
      "5  0.541740  \n",
      "6  0.504715  \n",
      "7  0.556558  \n",
      "\n",
      "--- Summary ---\n",
      "Mean accuracy: 0.5223119480794434\n",
      "Std  accuracy: 0.038374882991356024\n",
      "Mean roc_auc : 0.5233102149623776\n",
      "\n",
      "============================================================\n",
      " BLOCK BOOTSTRAP for AAPL\n",
      "95% CI accuracy: [0.5000, 0.5452]\n",
      "Bootstrap mean accuracy: 0.5225\n",
      "Selected features for AAPL based on precision:\n",
      "Running for AAPL with selected features (17)\n",
      "============================================================\n",
      " WALK-FORWARD RESULTS for AAPL\n",
      "   train_end_year  test_year  n_train  n_test  accuracy  precision    recall  \\\n",
      "0            2015       2016     1510     252  0.507937   0.520179  0.872180   \n",
      "1            2016       2017     1762     251  0.474104   0.666667  0.086957   \n",
      "2            2017       2018     2013     251  0.505976   0.514451  0.689922   \n",
      "3            2018       2019     2264     252  0.571429   0.578947  0.972789   \n",
      "4            2019       2020     2516     253  0.537549   0.544643  0.890511   \n",
      "5            2020       2021     2769     252  0.543651   0.551913  0.753731   \n",
      "6            2021       2022     3021     251  0.450199   0.429577  0.516949   \n",
      "7            2022       2023     3272     250  0.504000   0.593023  0.364286   \n",
      "\n",
      "    roc_auc  \n",
      "0  0.498452  \n",
      "1  0.543542  \n",
      "2  0.513915  \n",
      "3  0.507613  \n",
      "4  0.535993  \n",
      "5  0.502719  \n",
      "6  0.470243  \n",
      "7  0.551169  \n",
      "\n",
      "--- Summary ---\n",
      "Mean accuracy: 0.5118555205740811\n",
      "Std  accuracy: 0.03883740676335636\n",
      "Mean roc_auc : 0.5154558719632665\n",
      "\n",
      "============================================================\n",
      " BLOCK BOOTSTRAP for AAPL\n",
      "95% CI accuracy: [0.4910, 0.5333]\n",
      "Bootstrap mean accuracy: 0.5116\n",
      "Selected features for AAPL based on recall:\n",
      "Running for AAPL with selected features (11)\n",
      "============================================================\n",
      " WALK-FORWARD RESULTS for AAPL\n",
      "   train_end_year  test_year  n_train  n_test  accuracy  precision    recall  \\\n",
      "0            2015       2016     1510     252  0.515873   0.522822  0.947368   \n",
      "1            2016       2017     1762     251  0.482072   0.571429  0.231884   \n",
      "2            2017       2018     2013     251  0.482072   0.495798  0.457364   \n",
      "3            2018       2019     2264     252  0.559524   0.575000  0.938776   \n",
      "4            2019       2020     2516     253  0.553360   0.566667  0.744526   \n",
      "5            2020       2021     2769     252  0.563492   0.552174  0.947761   \n",
      "6            2021       2022     3021     251  0.474104   0.468468  0.881356   \n",
      "7            2022       2023     3272     250  0.548000   0.595745  0.600000   \n",
      "\n",
      "    roc_auc  \n",
      "0  0.493334  \n",
      "1  0.515775  \n",
      "2  0.499238  \n",
      "3  0.502883  \n",
      "4  0.572238  \n",
      "5  0.541740  \n",
      "6  0.504715  \n",
      "7  0.556558  \n",
      "\n",
      "--- Summary ---\n",
      "Mean accuracy: 0.5223119480794434\n",
      "Std  accuracy: 0.038374882991356024\n",
      "Mean roc_auc : 0.5233102149623776\n",
      "\n",
      "============================================================\n",
      " BLOCK BOOTSTRAP for AAPL\n",
      "95% CI accuracy: [0.5000, 0.5452]\n",
      "Bootstrap mean accuracy: 0.5225\n",
      "Selected features for AAPL based on roc_auc:\n",
      "Running for AAPL with selected features (12)\n",
      "============================================================\n",
      " WALK-FORWARD RESULTS for AAPL\n",
      "   train_end_year  test_year  n_train  n_test  accuracy  precision    recall  \\\n",
      "0            2015       2016     1510     252  0.511905   0.521008  0.932331   \n",
      "1            2016       2017     1762     251  0.498008   0.642857  0.195652   \n",
      "2            2017       2018     2013     251  0.505976   0.517241  0.581395   \n",
      "3            2018       2019     2264     252  0.559524   0.577586  0.911565   \n",
      "4            2019       2020     2516     253  0.565217   0.594406  0.620438   \n",
      "5            2020       2021     2769     252  0.543651   0.543779  0.880597   \n",
      "6            2021       2022     3021     251  0.494024   0.480349  0.932203   \n",
      "7            2022       2023     3272     250  0.532000   0.592000  0.528571   \n",
      "\n",
      "    roc_auc  \n",
      "0  0.468819  \n",
      "1  0.537579  \n",
      "2  0.490660  \n",
      "3  0.506706  \n",
      "4  0.563114  \n",
      "5  0.508411  \n",
      "6  0.500446  \n",
      "7  0.551039  \n",
      "\n",
      "--- Summary ---\n",
      "Mean accuracy: 0.5262880905639004\n",
      "Std  accuracy: 0.027811593563524164\n",
      "Mean roc_auc : 0.5158465740881435\n",
      "\n",
      "============================================================\n",
      " BLOCK BOOTSTRAP for AAPL\n",
      "95% CI accuracy: [0.5045, 0.5487]\n",
      "Bootstrap mean accuracy: 0.5269\n",
      "------GOOGL-----\n",
      "Selected features for GOOGL based on accuracy:\n",
      "Running for GOOGL with selected features (9)\n",
      "============================================================\n",
      " WALK-FORWARD RESULTS for GOOGL\n",
      "   train_end_year  test_year  n_train  n_test  accuracy  precision    recall  \\\n",
      "0            2015       2016     1510     252  0.539683   0.541401  0.658915   \n",
      "1            2016       2017     1762     251  0.498008   0.566372  0.453901   \n",
      "2            2017       2018     2013     251  0.521912   0.517073  0.834646   \n",
      "3            2018       2019     2264     252  0.511905   0.524664  0.873134   \n",
      "4            2019       2020     2516     253  0.513834   0.557895  0.731034   \n",
      "5            2020       2021     2769     252  0.460317   0.595238  0.173611   \n",
      "6            2021       2022     3021     251  0.442231   0.445344  0.973451   \n",
      "7            2022       2023     3272     250  0.532000   0.545024  0.845588   \n",
      "\n",
      "    roc_auc  \n",
      "0  0.562866  \n",
      "1  0.502450  \n",
      "2  0.576454  \n",
      "3  0.526309  \n",
      "4  0.472925  \n",
      "5  0.537359  \n",
      "6  0.509042  \n",
      "7  0.507675  \n",
      "\n",
      "--- Summary ---\n",
      "Mean accuracy: 0.5024862685527418\n",
      "Std  accuracy: 0.034389421689289906\n",
      "Mean roc_auc : 0.524385026184135\n",
      "\n",
      "============================================================\n",
      " BLOCK BOOTSTRAP for GOOGL\n",
      "95% CI accuracy: [0.4821, 0.5214]\n",
      "Bootstrap mean accuracy: 0.5010\n",
      "Selected features for GOOGL based on precision:\n",
      "Running for GOOGL with selected features (7)\n",
      "============================================================\n",
      " WALK-FORWARD RESULTS for GOOGL\n",
      "   train_end_year  test_year  n_train  n_test  accuracy  precision    recall  \\\n",
      "0            2015       2016     1510     252  0.539683   0.538922  0.697674   \n",
      "1            2016       2017     1762     251  0.501992   0.565574  0.489362   \n",
      "2            2017       2018     2013     251  0.505976   0.506494  0.921260   \n",
      "3            2018       2019     2264     252  0.527778   0.535545  0.843284   \n",
      "4            2019       2020     2516     253  0.498024   0.544554  0.758621   \n",
      "5            2020       2021     2769     252  0.567460   0.571429  0.972222   \n",
      "6            2021       2022     3021     251  0.450199   0.450199  1.000000   \n",
      "7            2022       2023     3272     250  0.536000   0.549505  0.816176   \n",
      "\n",
      "    roc_auc  \n",
      "0  0.578559  \n",
      "1  0.499613  \n",
      "2  0.558039  \n",
      "3  0.523210  \n",
      "4  0.459323  \n",
      "5  0.548354  \n",
      "6  0.512954  \n",
      "7  0.518898  \n",
      "\n",
      "--- Summary ---\n",
      "Mean accuracy: 0.5158889601266181\n",
      "Std  accuracy: 0.03524858227805391\n",
      "Mean roc_auc : 0.524868854696587\n",
      "\n",
      "============================================================\n",
      " BLOCK BOOTSTRAP for GOOGL\n",
      "95% CI accuracy: [0.4945, 0.5343]\n",
      "Bootstrap mean accuracy: 0.5145\n",
      "Selected features for GOOGL based on recall:\n",
      "Running for GOOGL with selected features (9)\n",
      "============================================================\n",
      " WALK-FORWARD RESULTS for GOOGL\n",
      "   train_end_year  test_year  n_train  n_test  accuracy  precision    recall  \\\n",
      "0            2015       2016     1510     252  0.539683   0.541401  0.658915   \n",
      "1            2016       2017     1762     251  0.498008   0.566372  0.453901   \n",
      "2            2017       2018     2013     251  0.521912   0.517073  0.834646   \n",
      "3            2018       2019     2264     252  0.511905   0.524664  0.873134   \n",
      "4            2019       2020     2516     253  0.513834   0.557895  0.731034   \n",
      "5            2020       2021     2769     252  0.460317   0.595238  0.173611   \n",
      "6            2021       2022     3021     251  0.442231   0.445344  0.973451   \n",
      "7            2022       2023     3272     250  0.532000   0.545024  0.845588   \n",
      "\n",
      "    roc_auc  \n",
      "0  0.562866  \n",
      "1  0.502450  \n",
      "2  0.576454  \n",
      "3  0.526309  \n",
      "4  0.472925  \n",
      "5  0.537359  \n",
      "6  0.509042  \n",
      "7  0.507675  \n",
      "\n",
      "--- Summary ---\n",
      "Mean accuracy: 0.5024862685527418\n",
      "Std  accuracy: 0.034389421689289906\n",
      "Mean roc_auc : 0.524385026184135\n",
      "\n",
      "============================================================\n",
      " BLOCK BOOTSTRAP for GOOGL\n",
      "95% CI accuracy: [0.4821, 0.5214]\n",
      "Bootstrap mean accuracy: 0.5010\n",
      "Selected features for GOOGL based on roc_auc:\n",
      "Running for GOOGL with selected features (29)\n",
      "============================================================\n",
      " WALK-FORWARD RESULTS for GOOGL\n",
      "   train_end_year  test_year  n_train  n_test  accuracy  precision    recall  \\\n",
      "0            2015       2016     1510     252  0.559524   0.560811  0.643411   \n",
      "1            2016       2017     1762     251  0.486056   0.833333  0.106383   \n",
      "2            2017       2018     2013     251  0.509960   0.517241  0.472441   \n",
      "3            2018       2019     2264     252  0.531746   0.600000  0.358209   \n",
      "4            2019       2020     2516     253  0.438735   0.528302  0.193103   \n",
      "5            2020       2021     2769     252  0.444444   0.625000  0.069444   \n",
      "6            2021       2022     3021     251  0.442231   0.444444  0.955752   \n",
      "7            2022       2023     3272     250  0.472000   0.666667  0.058824   \n",
      "\n",
      "    roc_auc  \n",
      "0  0.601437  \n",
      "1  0.541522  \n",
      "2  0.564453  \n",
      "3  0.519542  \n",
      "4  0.481737  \n",
      "5  0.554141  \n",
      "6  0.497627  \n",
      "7  0.519543  \n",
      "\n",
      "--- Summary ---\n",
      "Mean accuracy: 0.48558705944151115\n",
      "Std  accuracy: 0.04495032896662321\n",
      "Mean roc_auc : 0.53500022305143\n",
      "\n",
      "============================================================\n",
      " BLOCK BOOTSTRAP for GOOGL\n",
      "95% CI accuracy: [0.4617, 0.5060]\n",
      "Bootstrap mean accuracy: 0.4846\n",
      "------MSFT-----\n",
      "Selected features for MSFT based on accuracy:\n",
      "Running for MSFT with selected features (36)\n",
      "============================================================\n",
      " WALK-FORWARD RESULTS for MSFT\n",
      "   train_end_year  test_year  n_train  n_test  accuracy  precision    recall  \\\n",
      "0            2015       2016     1510     252  0.523810   0.520161  0.992308   \n",
      "1            2016       2017     1762     251  0.446215   0.333333  0.007246   \n",
      "2            2017       2018     2013     251  0.490040   0.622222  0.201439   \n",
      "3            2018       2019     2264     252  0.511905   0.587413  0.567568   \n",
      "4            2019       2020     2516     253  0.513834   0.581967  0.496503   \n",
      "5            2020       2021     2769     252  0.488095   0.512987  0.593985   \n",
      "6            2021       2022     3021     251  0.458167   0.457983  0.939655   \n",
      "7            2022       2023     3272     250  0.512000   0.735294  0.181159   \n",
      "\n",
      "    roc_auc  \n",
      "0  0.494515  \n",
      "1  0.515583  \n",
      "2  0.590249  \n",
      "3  0.506692  \n",
      "4  0.506294  \n",
      "5  0.491691  \n",
      "6  0.542209  \n",
      "7  0.542961  \n",
      "\n",
      "--- Summary ---\n",
      "Mean accuracy: 0.49300822833266966\n",
      "Std  accuracy: 0.028123779281088366\n",
      "Mean roc_auc : 0.5237742085731201\n",
      "\n",
      "============================================================\n",
      " BLOCK BOOTSTRAP for MSFT\n",
      "95% CI accuracy: [0.4732, 0.5179]\n",
      "Bootstrap mean accuracy: 0.4944\n",
      "Selected features for MSFT based on precision:\n",
      "Running for MSFT with selected features (8)\n",
      "============================================================\n",
      " WALK-FORWARD RESULTS for MSFT\n",
      "   train_end_year  test_year  n_train  n_test  accuracy  precision    recall  \\\n",
      "0            2015       2016     1510     252  0.480159   0.497238  0.692308   \n",
      "1            2016       2017     1762     251  0.474104   0.528302  0.405797   \n",
      "2            2017       2018     2013     251  0.573705   0.597561  0.705036   \n",
      "3            2018       2019     2264     252  0.492063   0.573529  0.527027   \n",
      "4            2019       2020     2516     253  0.541502   0.577143  0.706294   \n",
      "5            2020       2021     2769     252  0.535714   0.541237  0.789474   \n",
      "6            2021       2022     3021     251  0.450199   0.454918  0.956897   \n",
      "7            2022       2023     3272     250  0.528000   0.567568  0.608696   \n",
      "\n",
      "    roc_auc  \n",
      "0  0.498045  \n",
      "1  0.489676  \n",
      "2  0.588772  \n",
      "3  0.484278  \n",
      "4  0.542975  \n",
      "5  0.496304  \n",
      "6  0.519540  \n",
      "7  0.523163  \n",
      "\n",
      "--- Summary ---\n",
      "Mean accuracy: 0.5094308065435729\n",
      "Std  accuracy: 0.041593723053844664\n",
      "Mean roc_auc : 0.5178440058683611\n",
      "\n",
      "============================================================\n",
      " BLOCK BOOTSTRAP for MSFT\n",
      "95% CI accuracy: [0.4896, 0.5328]\n",
      "Bootstrap mean accuracy: 0.5107\n",
      "Selected features for MSFT based on recall:\n",
      "Running for MSFT with selected features (38)\n",
      "============================================================\n",
      " WALK-FORWARD RESULTS for MSFT\n",
      "   train_end_year  test_year  n_train  n_test  accuracy  precision    recall  \\\n",
      "0            2015       2016     1510     252  0.511905   0.514523  0.953846   \n",
      "1            2016       2017     1762     251  0.446215   0.333333  0.007246   \n",
      "2            2017       2018     2013     251  0.482072   0.578947  0.237410   \n",
      "3            2018       2019     2264     252  0.496032   0.600000  0.425676   \n",
      "4            2019       2020     2516     253  0.494071   0.551724  0.559441   \n",
      "5            2020       2021     2769     252  0.503968   0.519231  0.812030   \n",
      "6            2021       2022     3021     251  0.458167   0.456897  0.913793   \n",
      "7            2022       2023     3272     250  0.500000   0.709677  0.159420   \n",
      "\n",
      "    roc_auc  \n",
      "0  0.496658  \n",
      "1  0.505643  \n",
      "2  0.584211  \n",
      "3  0.511435  \n",
      "4  0.502606  \n",
      "5  0.483351  \n",
      "6  0.544636  \n",
      "7  0.533903  \n",
      "\n",
      "--- Summary ---\n",
      "Mean accuracy: 0.48655376142709417\n",
      "Std  accuracy: 0.02307182884956143\n",
      "Mean roc_auc : 0.5203054495334809\n",
      "\n",
      "============================================================\n",
      " BLOCK BOOTSTRAP for MSFT\n",
      "95% CI accuracy: [0.4657, 0.5094]\n",
      "Bootstrap mean accuracy: 0.4878\n",
      "Selected features for MSFT based on roc_auc:\n",
      "Running for MSFT with selected features (33)\n",
      "============================================================\n",
      " WALK-FORWARD RESULTS for MSFT\n",
      "   train_end_year  test_year  n_train  n_test  accuracy  precision    recall  \\\n",
      "0            2015       2016     1510     252  0.523810   0.520000  1.000000   \n",
      "1            2016       2017     1762     251  0.450199   0.500000  0.007246   \n",
      "2            2017       2018     2013     251  0.501992   0.634615  0.237410   \n",
      "3            2018       2019     2264     252  0.507937   0.586957  0.547297   \n",
      "4            2019       2020     2516     253  0.509881   0.576000  0.503497   \n",
      "5            2020       2021     2769     252  0.515873   0.524017  0.902256   \n",
      "6            2021       2022     3021     251  0.442231   0.450000  0.931034   \n",
      "7            2022       2023     3272     250  0.508000   0.727273  0.173913   \n",
      "\n",
      "    roc_auc  \n",
      "0  0.510467  \n",
      "1  0.516032  \n",
      "2  0.578944  \n",
      "3  0.502274  \n",
      "4  0.508201  \n",
      "5  0.499400  \n",
      "6  0.554662  \n",
      "7  0.551825  \n",
      "\n",
      "--- Summary ---\n",
      "Mean accuracy: 0.4949903476626151\n",
      "Std  accuracy: 0.030854589774627295\n",
      "Mean roc_auc : 0.5277253785110378\n",
      "\n",
      "============================================================\n",
      " BLOCK BOOTSTRAP for MSFT\n",
      "95% CI accuracy: [0.4751, 0.5189]\n",
      "Bootstrap mean accuracy: 0.4965\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tickers = [\"AAPL\", \"GOOGL\", \"MSFT\"]\n",
    "measurments = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "\n",
    "with open(\"../../models_results/feature_dict.json\", \"r\") as f:\n",
    "    feature_dict = json.load(f)\n",
    "\n",
    "\n",
    "def get_all_features(df):\n",
    "    return [c for c in df.columns if c not in [\"DATE\", \"index\", \"Target\"]]\n",
    "\n",
    "for share in tickers:\n",
    "    data = pd.read_csv(f\"../../data/all_data/all_{share}_data.csv\")\n",
    "    df_tmp = get_target(data, share)\n",
    "    features_aapl = get_all_features(df_tmp)\n",
    "    print(f\"------{share}-----\")\n",
    "    for stat in measurments:\n",
    "        selected_features = feature_dict[share][stat]\n",
    "        print(f\"Selected features for {share} based on {stat}:\")\n",
    "        # print(f\"Running for {share} with all features ({len(features_aapl)})\")\n",
    "        # run_stage4_for_ticker(data, share, features_aapl)\n",
    "        print(f\"Running for {share} with selected features ({len(selected_features)})\")\n",
    "        run_stage4_for_ticker(data, share, selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362594b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
