{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-29T14:50:49.154333Z",
     "start_time": "2026-01-29T14:50:49.142497Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.ma.extras import average\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "import json\n",
    "import optuna \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "### OWN FUNCTIONS \n",
    "from model_functions import *"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "markdown",
   "id": "7d4736df60fbdbd2",
   "metadata": {},
   "source": [
    "## Main Model: Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "id": "30b1d9284bfca591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T14:50:49.309243Z",
     "start_time": "2026-01-29T14:50:49.163525Z"
    }
   },
   "source": [
    "aapl_with_features = pd.read_csv('../data/all_data/all_AAPL_data.csv')\n",
    "googl_with_features = pd.read_csv('../data/all_data/all_GOOGL_data.csv')\n",
    "msft_with_features = pd.read_csv('../data/all_data/all_MSFT_data.csv')"
   ],
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "id": "b525133f192631ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T14:50:49.330431Z",
     "start_time": "2026-01-29T14:50:49.328358Z"
    }
   },
   "source": [
    "tickers = ['AAPL', 'GOOGL', 'MSFT']\n",
    "data_dict = {\n",
    "    'AAPL': aapl_with_features,\n",
    "    'GOOGL': googl_with_features,\n",
    "    'MSFT': msft_with_features\n",
    "}\n",
    "color_dict = {\n",
    "     'AAPL': 'grey',\n",
    "    'GOOGL': 'yellow',\n",
    "    'MSFT': 'green'\n",
    "}\n",
    "\n",
    "statistics = ['accuracy', 'precision_weighted', 'recall_weighted', 'roc_auc_ovr_weighted']\n",
    "#statistics = ['accuracy']"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "id": "5e35ef68c52d3804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T14:50:49.349672Z",
     "start_time": "2026-01-29T14:50:49.346755Z"
    }
   },
   "source": [
    "def get_tbm_target(df, ticker, horizon=5, pt_sl=[1.3,1]):\n",
    "    df = df.copy()\n",
    "    close = df[f'Close_{ticker}']\n",
    "    \n",
    "    log_ret = np.log(close / close.shift(1))\n",
    "    volatility = log_ret.rolling(window=20).std()\n",
    "    \n",
    "    targets = pd.Series(index=df.index, dtype=float)\n",
    "    \n",
    "    for i in range(len(df) - horizon):\n",
    "        price_start = close.iloc[i]\n",
    "        current_vol = volatility.iloc[i] ### dynamic barrier for each day\n",
    "        \n",
    "        upper_barrier = price_start * (1 + current_vol * pt_sl[0])\n",
    "        lower_barrier = price_start * (1 - current_vol * pt_sl[1])\n",
    "        \n",
    "        future_prices = close.iloc[i+1 : i+ 1 + horizon]\n",
    "        \n",
    "        targets.iloc[i] = 0\n",
    "        \n",
    "        for price_future in future_prices:\n",
    "            if price_future >= upper_barrier:\n",
    "                targets.iloc[i] = 1 # profit taking hit\n",
    "                break\n",
    "            elif price_future <= lower_barrier:\n",
    "                targets.iloc[i] = -1 # stop loss hit\n",
    "                break\n",
    "    df['Target'] = targets\n",
    "    return df.dropna(subset=['Target'])"
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "id": "155d602ba491d940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T14:50:49.368527Z",
     "start_time": "2026-01-29T14:50:49.365870Z"
    }
   },
   "source": [
    "def get_target(input_df, ticker):\n",
    "    df = input_df.copy()\n",
    "    df['Target'] = (df[f'Close_{ticker}'].shift(-1) > df[f'Close_{ticker}']).astype(int)\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "markdown",
   "id": "166d06b4139e38b7",
   "metadata": {},
   "source": [
    "### SEARCHING FOR BEST FEATURES BY USING RFECV"
   ]
  },
  {
   "cell_type": "code",
   "id": "bf2ac04c3d7cdc2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T14:50:49.404387Z",
     "start_time": "2026-01-29T14:50:49.399064Z"
    }
   },
   "source": [
    "def best_features(data_dict, tickers, pred_type):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    feature_dict = {}\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for i, share in enumerate(tickers):\n",
    "        feature_dict[share] = {}\n",
    "        df = pred_type(data_dict[share], share)\n",
    "        \n",
    "        banned_keywords = [\n",
    "            'Open_', 'High_', 'Low_', 'Close_', 'Volume_',\n",
    "            'rolling_max', 'rolling_min',\n",
    "            'CPI', 'Dollar_idx', 'FEDFUNDS', \n",
    "            'BBM_', 'BBU_', 'BBL_',\n",
    "            'MACD_', 'MACDs_' \n",
    "        ]\n",
    "        \n",
    "        cols_to_ban = []\n",
    "        for col in df.columns:\n",
    "            if any(ban in col for ban in banned_keywords):\n",
    "                if 'change' in col: continue\n",
    "                if 'diff' in col: continue\n",
    "                if 'MACDh' in col: continue\n",
    "                \n",
    "                cols_to_ban.append(col)\n",
    "        \n",
    "        safe_cols = [c for c in df.columns if c not in cols_to_ban]\n",
    "        df = df[safe_cols]\n",
    "        \n",
    "        features = [col for col in df.columns if col not in ['Target', 'index', 'DATE', f'Close_{share}', f'Open_{share}', f'High_{share}', f'Low_{share}', f'Volume_{share}']]\n",
    "\n",
    "        to_remove = [f'Volume_{share}_lag1', f'Volume_{share}_lag2', f'Volume_{share}_lag3', f'Volume_{share}_lag5',\n",
    "                         f'RSI_14_lag1', 'RSI_14_lag2', 'RSI_14_lag3', 'RSI_14_lag5', 'log_return_lag1', 'log_return_lag2',\n",
    "                         'log_return_lag3', 'log_return_lag5']\n",
    "\n",
    "        '''if share == 'AAPL':\n",
    "            additional_to_remove = ['rolling_max_20', 'rolling_max_20', 'dist_to_max_20', 'dist_to_min_20', 'rolling_max_60', 'rolling_max_60', 'dist_to_max_60', 'dist_to_min_60']\n",
    "            to_remove += additional_to_remove\n",
    "            '''\n",
    "\n",
    "        features = [f for f in features if f not in to_remove]\n",
    "\n",
    "        X = df[features]\n",
    "        y = df['Target']\n",
    "        y_encoded = le.fit_transform(y)\n",
    "\n",
    "        model_judge_rf = RandomForestClassifier(n_estimators=100, max_depth=4, random_state=42, n_jobs=-1)\n",
    "\n",
    "        # Second model to check\n",
    "        model_judge_xgb = XGBClassifier(\n",
    "            n_estimators=50,\n",
    "            max_depth=4,\n",
    "            learning_rate=0.1,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            eval_metric='logloss',\n",
    "            \n",
    "            use_label_encoder=False\n",
    "        )\n",
    "\n",
    "        ### test on different models for best acc for each company\n",
    "        '''if share != 'MSFT':\n",
    "            model_judge = model_judge_rf\n",
    "        else:\n",
    "            df = pred_type(data_dict[share], share)\n",
    "            df = df.iloc[20:]\n",
    "            model_judge = model_judge_xgb\n",
    "            '''\n",
    "\n",
    "        model_judge = model_judge_rf\n",
    "\n",
    "        cv_split = TimeSeriesSplit(n_splits=5)\n",
    "        min_feats = 15 if share == 'AAPL' else 10\n",
    "        rfecv = RFECV(\n",
    "                estimator=model_judge,\n",
    "                min_features_to_select=min_feats,\n",
    "                step=1,\n",
    "                cv=cv_split,\n",
    "                scoring='precision_weighted',\n",
    "                n_jobs=-1,)\n",
    "\n",
    "        rfecv.fit(X, y_encoded)\n",
    "\n",
    "        print(f\"Optimal features numer by RFECV : {rfecv.n_features_}\")\n",
    "        selected_features = [f for f, s in zip(features, rfecv.support_) if s]\n",
    "\n",
    "        X_refined = X[selected_features]\n",
    "        desired_features = min(len(selected_features), 20)\n",
    "        rfe_final = RFE(\n",
    "                    estimator=model_judge,\n",
    "                    n_features_to_select=desired_features,\n",
    "                    step=1\n",
    "                )\n",
    "\n",
    "        rfe_final.fit(X_refined, y_encoded)\n",
    "        final_features = [f for f, s in zip(selected_features, rfe_final.support_) if s]\n",
    "\n",
    "        selected_features = final_features\n",
    "        must_have_features = ['FinBERT_MA7', 'DGS10', 'Dollar_idx']\n",
    "        \n",
    "        for feature in must_have_features:\n",
    "            if feature in X.columns:\n",
    "                if feature not in selected_features:\n",
    "                    selected_features.append(feature)\n",
    "                    \n",
    "        print(f\"Winner features: ({len(selected_features)}):\")\n",
    "        print(selected_features)\n",
    "        feature_dict[share] = selected_features\n",
    "\n",
    "    return feature_dict"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "c85ac6fab613a834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T14:51:33.935248Z",
     "start_time": "2026-01-29T14:50:49.409428Z"
    }
   },
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "tbm = best_features(data_dict, tickers, pred_type=get_tbm_target) \n",
    "with open('../selected_features/feature_dict_tbm.json', 'w') as f:\n",
    "    json.dump(tbm, f, indent=4)   \n",
    "print(tbm)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal features numer by RFECV : 20\n",
      "Winner features: (21):\n",
      "['RSI_14', 'MACDh_12_26_9', 'ATRr_14', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0', 'DGS10', 'RSI_14_MSFT', 'MACDh_12_26_9_MSFT', 'BBB_20_2.0_2.0_MSFT', 'BBP_20_2.0_2.0_MSFT', 'RSI_14_GOOGL', 'ATRr_14_GOOGL', 'BBB_20_2.0_2.0_GOOGL', 'cusum', 'cusum_pos', 'cusum_neg', 'dist_to_max_20', 'dist_to_min_20', 'dist_to_max_60', 'dist_to_min_60', 'FinBERT_MA7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal features numer by RFECV : 38\n",
      "Winner features: (21):\n",
      "['RSI_14', 'MACDh_12_26_9', 'ATRr_14', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0', 'DGS10', 'RSI_14_MSFT', 'MACDh_12_26_9_MSFT', 'ATRr_14_MSFT', 'BBB_20_2.0_2.0_MSFT', 'BBP_20_2.0_2.0_MSFT', 'MACDh_12_26_9_AAPL', 'ATRr_14_AAPL', 'BBB_20_2.0_2.0_AAPL', 'cusum', 'cusum_pos', 'cusum_neg', 'dist_to_min_20', 'dist_to_min_60', 'Dist_to_SMA200_GOOGL', 'FinBERT_MA7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal features numer by RFECV : 15\n",
      "Winner features: (17):\n",
      "['RSI_14', 'MACDh_12_26_9', 'ATRr_14', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0', 'MACDh_12_26_9_AAPL', 'ATRr_14_AAPL', 'BBB_20_2.0_2.0_AAPL', 'BBP_20_2.0_2.0_AAPL', 'cusum', 'cusum_pos', 'cusum_neg', 'dist_to_min_20', 'dist_to_max_60', 'dist_to_min_60', 'FinBERT_MA7', 'DGS10']\n",
      "{'AAPL': ['RSI_14', 'MACDh_12_26_9', 'ATRr_14', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0', 'DGS10', 'RSI_14_MSFT', 'MACDh_12_26_9_MSFT', 'BBB_20_2.0_2.0_MSFT', 'BBP_20_2.0_2.0_MSFT', 'RSI_14_GOOGL', 'ATRr_14_GOOGL', 'BBB_20_2.0_2.0_GOOGL', 'cusum', 'cusum_pos', 'cusum_neg', 'dist_to_max_20', 'dist_to_min_20', 'dist_to_max_60', 'dist_to_min_60', 'FinBERT_MA7'], 'GOOGL': ['RSI_14', 'MACDh_12_26_9', 'ATRr_14', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0', 'DGS10', 'RSI_14_MSFT', 'MACDh_12_26_9_MSFT', 'ATRr_14_MSFT', 'BBB_20_2.0_2.0_MSFT', 'BBP_20_2.0_2.0_MSFT', 'MACDh_12_26_9_AAPL', 'ATRr_14_AAPL', 'BBB_20_2.0_2.0_AAPL', 'cusum', 'cusum_pos', 'cusum_neg', 'dist_to_min_20', 'dist_to_min_60', 'Dist_to_SMA200_GOOGL', 'FinBERT_MA7'], 'MSFT': ['RSI_14', 'MACDh_12_26_9', 'ATRr_14', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0', 'MACDh_12_26_9_AAPL', 'ATRr_14_AAPL', 'BBB_20_2.0_2.0_AAPL', 'BBP_20_2.0_2.0_AAPL', 'cusum', 'cusum_pos', 'cusum_neg', 'dist_to_min_20', 'dist_to_max_60', 'dist_to_min_60', 'FinBERT_MA7', 'DGS10']}\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T14:52:13.482398Z",
     "start_time": "2026-01-29T14:51:33.976808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "binary = best_features(data_dict, tickers, pred_type=get_target) \n",
    "with open('../selected_features/feature_dict_binary.json', 'w') as f:\n",
    "    json.dump(binary, f, indent=4)   \n",
    "print(binary)"
   ],
   "id": "eebe674cf2516637",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal features numer by RFECV : 33\n",
      "Winner features: (22):\n",
      "['RSI_14', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0', 'VIX_percent', 'RSI_14_MSFT', 'MACDh_12_26_9_MSFT', 'BBB_20_2.0_2.0_MSFT', 'RSI_14_GOOGL', 'MACDh_12_26_9_GOOGL', 'BBB_20_2.0_2.0_GOOGL', 'BBP_20_2.0_2.0_GOOGL', 'Dollar_idx_change', 'VIX_change', 'log_return', 'cusum', 'cusum_pos', 'dist_to_max_20', 'dist_to_min_20', 'dist_to_max_60', 'Dist_to_SMA200_AAPL', 'FinBERT_MA7', 'DGS10']\n",
      "Optimal features numer by RFECV : 29\n",
      "Winner features: (21):\n",
      "['MACDh_12_26_9', 'BBB_20_2.0_2.0', 'DGS10', 'USEPUINDXD', 'VIX_percent', 'RSI_14_MSFT', 'ATRr_14_MSFT', 'BBB_20_2.0_2.0_MSFT', 'BBP_20_2.0_2.0_MSFT', 'RSI_14_AAPL', 'MACDh_12_26_9_AAPL', 'ATRr_14_AAPL', 'BBB_20_2.0_2.0_AAPL', 'Dollar_idx_change', 'VIX_change', 'log_return', 'cusum', 'cusum_pos', 'cusum_neg', 'dist_to_min_20', 'FinBERT_MA7']\n",
      "Optimal features numer by RFECV : 23\n",
      "Winner features: (22):\n",
      "['RSI_14', 'BBB_20_2.0_2.0', 'USEPUINDXD', 'VIX_percent', 'RSI_14_AAPL', 'ATRr_14_AAPL', 'BBB_20_2.0_2.0_AAPL', 'BBP_20_2.0_2.0_AAPL', 'RSI_14_GOOGL', 'MACDh_12_26_9_GOOGL', 'ATRr_14_GOOGL', 'Dollar_idx_change', 'VIX_change', 'log_return', 'cusum', 'cusum_pos', 'cusum_neg', 'dist_to_min_20', 'dist_to_max_60', 'dist_to_min_60', 'FinBERT_MA7', 'DGS10']\n",
      "{'AAPL': ['RSI_14', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0', 'VIX_percent', 'RSI_14_MSFT', 'MACDh_12_26_9_MSFT', 'BBB_20_2.0_2.0_MSFT', 'RSI_14_GOOGL', 'MACDh_12_26_9_GOOGL', 'BBB_20_2.0_2.0_GOOGL', 'BBP_20_2.0_2.0_GOOGL', 'Dollar_idx_change', 'VIX_change', 'log_return', 'cusum', 'cusum_pos', 'dist_to_max_20', 'dist_to_min_20', 'dist_to_max_60', 'Dist_to_SMA200_AAPL', 'FinBERT_MA7', 'DGS10'], 'GOOGL': ['MACDh_12_26_9', 'BBB_20_2.0_2.0', 'DGS10', 'USEPUINDXD', 'VIX_percent', 'RSI_14_MSFT', 'ATRr_14_MSFT', 'BBB_20_2.0_2.0_MSFT', 'BBP_20_2.0_2.0_MSFT', 'RSI_14_AAPL', 'MACDh_12_26_9_AAPL', 'ATRr_14_AAPL', 'BBB_20_2.0_2.0_AAPL', 'Dollar_idx_change', 'VIX_change', 'log_return', 'cusum', 'cusum_pos', 'cusum_neg', 'dist_to_min_20', 'FinBERT_MA7'], 'MSFT': ['RSI_14', 'BBB_20_2.0_2.0', 'USEPUINDXD', 'VIX_percent', 'RSI_14_AAPL', 'ATRr_14_AAPL', 'BBB_20_2.0_2.0_AAPL', 'BBP_20_2.0_2.0_AAPL', 'RSI_14_GOOGL', 'MACDh_12_26_9_GOOGL', 'ATRr_14_GOOGL', 'Dollar_idx_change', 'VIX_change', 'log_return', 'cusum', 'cusum_pos', 'cusum_neg', 'dist_to_min_20', 'dist_to_max_60', 'dist_to_min_60', 'FinBERT_MA7', 'DGS10']}\n"
     ]
    }
   ],
   "execution_count": 80
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
