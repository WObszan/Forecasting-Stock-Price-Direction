{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T13:57:56.710402Z",
     "start_time": "2026-01-25T13:57:56.703191Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.ma.extras import average\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "import json\n",
    "import optuna \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "### OWN FUNCTIONS \n",
    "from model_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4736df60fbdbd2",
   "metadata": {},
   "source": [
    "## Main Model: Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30b1d9284bfca591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T13:57:56.810098Z",
     "start_time": "2026-01-25T13:57:56.713427Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_with_features = pd.read_csv('../data/all_data/all_AAPL_data.csv')\n",
    "googl_with_features = pd.read_csv('../data/all_data/all_GOOGL_data.csv')\n",
    "msft_with_features = pd.read_csv('../data/all_data/all_MSFT_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b525133f192631ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T13:57:56.828838Z",
     "start_time": "2026-01-25T13:57:56.827171Z"
    }
   },
   "outputs": [],
   "source": [
    "tickers = ['AAPL', 'GOOGL', 'MSFT']\n",
    "data_dict = {\n",
    "    'AAPL': aapl_with_features,\n",
    "    'GOOGL': googl_with_features,\n",
    "    'MSFT': msft_with_features\n",
    "}\n",
    "color_dict = {\n",
    "     'AAPL': 'grey',\n",
    "    'GOOGL': 'yellow',\n",
    "    'MSFT': 'green'\n",
    "}\n",
    "\n",
    "statistics = ['accuracy', 'precision_weighted', 'recall_weighted', 'roc_auc_ovr_weighted']\n",
    "#statistics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e35ef68c52d3804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T13:57:56.846567Z",
     "start_time": "2026-01-25T13:57:56.843904Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tbm_target(df, ticker, horizon=5, pt_sl=[1,1.5]):\n",
    "    df = df.copy()\n",
    "    close = df[f'Close_{ticker}']\n",
    "    \n",
    "    log_ret = np.log(close / close.shift(1))\n",
    "    volatility = log_ret.rolling(window=20).std()\n",
    "    \n",
    "    targets = pd.Series(index=df.index, dtype=float)\n",
    "    \n",
    "    for i in range(len(df) - horizon):\n",
    "        price_start = close.iloc[i]\n",
    "        current_vol = volatility.iloc[i] ### dynamic barrier for each day\n",
    "        \n",
    "        upper_barrier = price_start * (1 + current_vol * pt_sl[0])\n",
    "        lower_barrier = price_start * (1 - current_vol * pt_sl[1])\n",
    "        \n",
    "        future_prices = close.iloc[i+1 : i+ 1 + horizon]\n",
    "        \n",
    "        targets.iloc[i] = 0\n",
    "        \n",
    "        for price_future in future_prices:\n",
    "            if price_future >= upper_barrier:\n",
    "                targets.iloc[i] = 1 # profit taking hit\n",
    "                break\n",
    "            elif price_future <= lower_barrier:\n",
    "                targets.iloc[i] = -1 # stop loss hit\n",
    "                break\n",
    "    df['Target'] = targets\n",
    "    return df.dropna(subset=['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "155d602ba491d940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T13:57:56.864624Z",
     "start_time": "2026-01-25T13:57:56.862266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'DATE', 'Close_MSFT', 'High_MSFT', 'Low_MSFT', 'Open_MSFT',\n",
      "       'Volume_MSFT', 'RSI_14', 'MACD_12_26_9', 'MACDh_12_26_9',\n",
      "       'MACDs_12_26_9', 'ATRr_14', 'BBL_20_2.0_2.0', 'BBM_20_2.0_2.0',\n",
      "       'BBU_20_2.0_2.0', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0', 'Target',\n",
      "       'FEDFUNDS', 'DGS10', 'CPI', 'Dollar_idx', 'USEPUINDXD', 'Close_VIX',\n",
      "       'High_VIX', 'Low_VIX', 'Open_VIX', 'VIX_percent', 'Is_Panic', 'Is_Calm',\n",
      "       'Is_Uncertain', 'Close_AAPL', 'High_AAPL', 'Low_AAPL', 'Open_AAPL',\n",
      "       'Volume_AAPL', 'Close_GOOGL', 'High_GOOGL', 'Low_GOOGL', 'Open_GOOGL',\n",
      "       'Volume_GOOGL', 'log_return', 'cusum', 'cusum_pos', 'cusum_neg',\n",
      "       'anomaly_raw', 'is_anomaly'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(msft_with_features.columns[:47])\n",
    "def get_target(input_df, ticker):\n",
    "    df = input_df.copy()\n",
    "    df['Target'] = (df[f'Close_{ticker}'].shift(-1) > df[f'Close_{ticker}']).astype(int)\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166d06b4139e38b7",
   "metadata": {},
   "source": [
    "### SEARCHING FOR BEST FEATURES BY USING RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf2ac04c3d7cdc2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T13:57:56.885196Z",
     "start_time": "2026-01-25T13:57:56.880718Z"
    }
   },
   "outputs": [],
   "source": [
    "def best_features(data_dict, tickers):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    feature_dict = {}\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for i, share in enumerate(tickers):\n",
    "        feature_dict[share] = {}\n",
    "        df = get_tbm_target(data_dict[share], share)\n",
    "        features = [col for col in df.columns if col not in ['Target', 'index', 'DATE', f'Close_{share}', f'Open_{share}', f'High_{share}', f'Low_{share}', f'Volume_{share}']]\n",
    "\n",
    "        to_remove = [f'Volume_{share}_lag1', f'Volume_{share}_lag2', f'Volume_{share}_lag3', f'Volume_{share}_lag5',\n",
    "                         f'RSI_14_lag1', 'RSI_14_lag2', 'RSI_14_lag3', 'RSI_14_lag5', 'log_return_lag1', 'log_return_lag2',\n",
    "                         'log_return_lag3', 'log_return_lag5']\n",
    "\n",
    "        '''if share == 'AAPL':\n",
    "            additional_to_remove = ['rolling_max_20', 'rolling_max_20', 'dist_to_max_20', 'dist_to_min_20', 'rolling_max_60', 'rolling_max_60', 'dist_to_max_60', 'dist_to_min_60']\n",
    "            to_remove += additional_to_remove\n",
    "            '''\n",
    "\n",
    "        features = [f for f in features if f not in to_remove]\n",
    "\n",
    "        X = df[features]\n",
    "        y = df['Target']\n",
    "        y_encoded = le.fit_transform(y)\n",
    "\n",
    "        model_judge_rf = RandomForestClassifier(n_estimators=100, max_depth=4, random_state=42, n_jobs=-1)\n",
    "\n",
    "        # Second model to check\n",
    "        model_judge_xgb = XGBClassifier(\n",
    "            n_estimators=50,\n",
    "            max_depth=4,\n",
    "            learning_rate=0.1,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            eval_metric='logloss',\n",
    "            \n",
    "            use_label_encoder=False\n",
    "        )\n",
    "\n",
    "        ### test on different models for best acc for each company\n",
    "        '''if share != 'MSFT':\n",
    "            model_judge = model_judge_rf\n",
    "        else:\n",
    "            model_judge = model_judge_xgb\n",
    "            '''\n",
    "\n",
    "        model_judge = model_judge_xgb\n",
    "\n",
    "        cv_split = TimeSeriesSplit(n_splits=5)\n",
    "        min_feats = 15 if share == 'AAPL' else 10\n",
    "        rfecv = RFECV(\n",
    "                estimator=model_judge,\n",
    "                min_features_to_select=min_feats,\n",
    "                step=1,\n",
    "                cv=cv_split,\n",
    "                scoring='f1_weighted',\n",
    "                n_jobs=-1,)\n",
    "\n",
    "        rfecv.fit(X, y_encoded)\n",
    "\n",
    "        print(f\"Optimal features numer by RFECV : {rfecv.n_features_}\")\n",
    "        selected_features = [f for f, s in zip(features, rfecv.support_) if s]\n",
    "\n",
    "        X_refined = X[selected_features]\n",
    "        desired_features = min(len(selected_features), 20)\n",
    "        rfe_final = RFE(\n",
    "                    estimator=model_judge,\n",
    "                    n_features_to_select=desired_features,\n",
    "                    step=1\n",
    "                )\n",
    "\n",
    "        rfe_final.fit(X_refined, y_encoded)\n",
    "        final_features = [f for f, s in zip(selected_features, rfe_final.support_) if s]\n",
    "\n",
    "        selected_features = final_features\n",
    "        print(f\"Winner features: ({len(selected_features)}):\")\n",
    "        print(selected_features)\n",
    "        feature_dict[share] = selected_features\n",
    "\n",
    "    with open(\"../selected_features/feature_dict.json\", \"w\") as f:\n",
    "        json.dump(feature_dict, f, indent=4)\n",
    "\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c85ac6fab613a834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T13:59:00.940612Z",
     "start_time": "2026-01-25T13:57:56.901278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal features numer by RFECV : 34\n",
      "Winner features: (15):\n",
      "['MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9', 'ATRr_14', 'BBL_20_2.0_2.0', 'BBM_20_2.0_2.0', 'BBB_20_2.0_2.0', 'FEDFUNDS', 'DGS10', 'CPI', 'Dollar_idx', 'Low_VIX', 'Open_VIX', 'Close_GOOGL', 'cusum_neg']\n",
      "Optimal features numer by RFECV : 27\n",
      "Winner features: (27):\n",
      "['MACDh_12_26_9', 'MACDs_12_26_9', 'BBL_20_2.0_2.0', 'BBM_20_2.0_2.0', 'BBU_20_2.0_2.0', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0', 'FEDFUNDS', 'DGS10', 'CPI', 'Dollar_idx', 'Close_VIX', 'High_VIX', 'Low_VIX', 'Open_VIX', 'Is_Panic', 'Close_MSFT', 'High_MSFT', 'Low_MSFT', 'Open_MSFT', 'Close_AAPL', 'High_AAPL', 'Low_AAPL', 'Open_AAPL', 'cusum', 'cusum_pos', 'cusum_neg']\n",
      "Optimal features numer by RFECV : 30\n",
      "Winner features: (15):\n",
      "['RSI_14', 'BBL_20_2.0_2.0', 'BBU_20_2.0_2.0', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0', 'CPI', 'Dollar_idx', 'Close_VIX', 'High_VIX', 'Close_AAPL', 'High_AAPL', 'Open_AAPL', 'High_GOOGL', 'Open_GOOGL', 'cusum_pos']\n",
      "{'AAPL': ['MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9', 'ATRr_14', 'BBL_20_2.0_2.0', 'BBM_20_2.0_2.0', 'BBB_20_2.0_2.0', 'FEDFUNDS', 'DGS10', 'CPI', 'Dollar_idx', 'Low_VIX', 'Open_VIX', 'Close_GOOGL', 'cusum_neg'], 'GOOGL': ['MACDh_12_26_9', 'MACDs_12_26_9', 'BBL_20_2.0_2.0', 'BBM_20_2.0_2.0', 'BBU_20_2.0_2.0', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0', 'FEDFUNDS', 'DGS10', 'CPI', 'Dollar_idx', 'Close_VIX', 'High_VIX', 'Low_VIX', 'Open_VIX', 'Is_Panic', 'Close_MSFT', 'High_MSFT', 'Low_MSFT', 'Open_MSFT', 'Close_AAPL', 'High_AAPL', 'Low_AAPL', 'Open_AAPL', 'cusum', 'cusum_pos', 'cusum_neg'], 'MSFT': ['RSI_14', 'BBL_20_2.0_2.0', 'BBU_20_2.0_2.0', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0', 'CPI', 'Dollar_idx', 'Close_VIX', 'High_VIX', 'Close_AAPL', 'High_AAPL', 'Open_AAPL', 'High_GOOGL', 'Open_GOOGL', 'cusum_pos']}\n"
     ]
    }
   ],
   "source": [
    "bf = best_features(data_dict, tickers) \n",
    "print(bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db2643261bd547d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T13:59:00.962643Z",
     "start_time": "2026-01-25T13:59:00.958393Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_train(tickers, feature_dict):\n",
    "    result_dict = {}\n",
    "\n",
    "    for i, share in enumerate(tickers):\n",
    "        df = get_tbm_target(data_dict, share)\n",
    "        features = [col for col in df.columns if col not in ['Target', 'index', 'DATE']]\n",
    "\n",
    "        X = df[features]\n",
    "        y = df['Target']\n",
    "        result_dict = {}\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "        selected_cols = feature_dict[share]\n",
    "\n",
    "        rf_pipeline = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('rf',\n",
    "                 RandomForestClassifier(n_estimators=100, max_depth=3, min_samples_leaf=10, random_state=42, n_jobs=-1))\n",
    "            ])\n",
    "\n",
    "        svm_pipeline = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('svc', SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42)),\n",
    "            ])\n",
    "\n",
    "        xgb_pipeline = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('xgb',\n",
    "                 XGBClassifier(n_estimators=50, max_depth=4, learning_rate=0.1, eval_metric='logloss', random_state=42,\n",
    "                               n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "        main_model = VotingClassifier(\n",
    "                estimators=[('xgb', xgb_pipeline), ('svc', svm_pipeline), ('rf', rf_pipeline), ],\n",
    "                voting='soft')\n",
    "\n",
    "        main_model.fit(X_train[selected_cols], y_train)\n",
    "\n",
    "        y_pred = main_model.predict(X_test[selected_cols])\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "        print('*' * 40)\n",
    "        print(f\"Results for {share}:\")\n",
    "        print(\"Accuracy:\", acc)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"ROC AUC score:\", roc_auc)\n",
    "        result_dict[share] = [acc, precision, recall, roc_auc]\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d6c44f0099ce13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T13:59:01.015367Z",
     "start_time": "2026-01-25T13:59:00.979443Z"
    }
   },
   "outputs": [],
   "source": [
    "result_dict = model_train(tickers, feature_dict=bf)\n",
    "print(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a2c40cca10c9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T13:59:01.018025Z",
     "start_time": "2026-01-25T12:52:06.060205Z"
    }
   },
   "outputs": [],
   "source": [
    "for share in tickers:\n",
    "    df_to_save = pd.DataFrame.from_dict(\n",
    "        result_dict[share], \n",
    "        orient='index',\n",
    "        columns=['accuracy', 'precision', 'recall', 'roc_auc'])\n",
    "    print('*'*10, f'Results', '*'*10)\n",
    "    print(df_to_save)\n",
    "    df_to_save.to_csv(f'../models_results/main_model_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8781dd1753a41cc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T13:59:01.018269Z",
     "start_time": "2026-01-25T10:38:09.849823Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_results = pd.read_csv('../models_results/RF_results.csv')\n",
    "svm_results = pd.read_csv('../models_results/SVM_results.csv')\n",
    "xgb_results = pd.read_csv('../models_results/XGB_results.csv')\n",
    "lr_results = pd.read_csv('../models_results/LR_results.csv')\n",
    "bs1_results = pd.read_csv('../models_results/bs1_results.csv')\n",
    "bs2_results = pd.read_csv('../models_results/bs2_results.csv')\n",
    "bs3_results = pd.read_csv('../models_results/bs3_results.csv')\n",
    "main_model_acc = pd.read_csv('../models_results/main_model_results_by_accuracy.csv')\n",
    "main_model_precision = pd.read_csv('../models_results/main_model_results_by_precision.csv')\n",
    "main_model_recall = pd.read_csv('../models_results/main_model_results_by_recall.csv')\n",
    "main_model_roc_auc = pd.read_csv('../models_results/main_model_results_by_roc_auc.csv')\n",
    "\n",
    "bs1_results['Model'] = 'Based on yesterday'\n",
    "bs2_results['Model'] = 'Always rise'\n",
    "bs3_results['Model'] = 'Based on SMA'\n",
    "rf_results['Model'] = 'Random Forest'\n",
    "svm_results['Model'] = 'SVM'\n",
    "xgb_results['Model'] = 'XGBoost'\n",
    "lr_results['Model'] = 'Logistic Regression'\n",
    "main_model_acc['Model'] = 'Ensemble (Main)'\n",
    "main_model_precision['Model'] = 'Ensemble (Main)'\n",
    "main_model_recall['Model'] = 'Ensemble (Main)'\n",
    "main_model_roc_auc['Model'] = 'Ensemble (Main)'\n",
    "\n",
    "all_dfs = [bs1_results, bs2_results, bs3_results, rf_results, svm_results, xgb_results, lr_results, main_model_acc]\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(20, 60))\n",
    "\n",
    "combined_df = pd.concat(all_dfs)\n",
    "    \n",
    "if 'Unnamed: 0' in combined_df.columns:\n",
    "    combined_df = combined_df.rename(columns={'Unnamed: 0': 'Ticker'})\n",
    "    \n",
    "combined_df = combined_df.sort_values(by=['Ticker'], ascending=[True, False])\n",
    "    \n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "    \n",
    "print('*' * 40)\n",
    "print(combined_df)\n",
    "    \n",
    "for i, t in enumerate(combined_df['Ticker'].unique()):\n",
    "    subsets = combined_df[combined_df['Ticker'] == t]\n",
    "    subsets = subsets.sort_values(by='accuracy', ascending=False)\n",
    "        \n",
    "    y_min = subsets.min() - 0.03\n",
    "    y_max = subsets.max() + 0.03\n",
    "        \n",
    "    axes[i].bar(subsets['Model'], subsets, color=color_dict[t])\n",
    "    axes[i].set_title(f'Share: {t}, prediction:', size=20)\n",
    "    axes[i].set_ylim(y_min, ymax=y_max)\n",
    "    axes[i].grid(axis='x', alpha=0.5, linestyle='--')\n",
    "    axes[i].tick_params(axis='x', labelsize=15, labelrotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d49ed88c8dbcba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T13:59:01.018553Z",
     "start_time": "2026-01-24T21:20:44.442989Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
